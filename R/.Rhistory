# order the data frame by regions and area
DAT <- DAT[order(DAT$REALM),]
# transform area and tree density
DAT$Area_km <- log(DAT$Area_km)
DAT$Tree_dens <- log(DAT$Tree_dens)
# remove NAs
DAT <- DAT[rowSums(is.na(DAT)) == 0,]
# mean and sd of Area (will be used later to bring these to their origina scale)
A.mean <- mean(DAT$Area_km)
A.sd <- sd(DAT$Area_km)
# means and sd of the rest of the variables
centr <- attributes(scale(DAT[,2:12]))$'scaled:center'
scale <- attributes(scale(DAT[,2:12]))$'scaled:scale'
scale.tab <- data.frame(var=names(centr), centr, scale)
write.csv(scale.tab, file="scale_tab.csv", row.names = FALSE)
# do the actual scaling
DAT[,2:12] <- scale(DAT[,2:12])
################################################################################
# 2. THE MODEL FORMULAS
################################################################################
REALM.formula <- S ~ REALM + poly(Area_km,3):REALM +
Tree_dens + Tree_dens:Area_km +
min_DBH + min_DBH:Area_km +
GPP + GPP:Area_km +
ANN_T + ANN_T:Area_km +
ISO_T + ISO_T:Area_km +
MIN_P + MIN_P:Area_km +
P_SEAS + P_SEAS:Area_km +
ALT_DIF + ALT_DIF:Area_km +
ISLAND + ISLAND:Area_km
SMOOTH.formula <- S ~ s(Lat, Lon, by=DAT_TYPE, bs="sos", k=14) +
poly(Area_km, 3) +
Tree_dens + Tree_dens:Area_km +
min_DBH + min_DBH:Area_km +
GPP + GPP:Area_km +
ANN_T + ANN_T:Area_km +
ISO_T + ISO_T:Area_km +
MIN_P + MIN_P:Area_km +
P_SEAS + P_SEAS:Area_km +
ALT_DIF + ALT_DIF:Area_km +
ISLAND + ISLAND:Area_km
################################################################################
# 3. FIT THE MODELS
################################################################################
gam.REALM <- gam(REALM.formula, data=DAT, family="nb")
summary(gam.REALM)
save(gam.REALM, file="../STAN_models/gam_REALM.Rdata")
gam.SMOOTH <- gam(SMOOTH.formula, data = DAT, family="nb")
summary(gam.SMOOTH)
save(gam.SMOOTH, file="../STAN_models/gam_SMOOTH.Rdata")
summary(DAT)
282/5
1335/5
1335/4
282/4
?CVgam
library(gamclass)
CVgam(REALM.formula, data=DAT, family="nb", nfold = 5)
nfolds <- 5
case.folds <- rep(1:nfolds,length.out=nrow(DAT))
case.folds
# divide the cases as evenly as possible
case.folds <- sample(case.folds) # randomly permute the order
gam.REALM
summary(gam.REALM)
a <- summary(gam.REALM)
a$dev.expl
preds <- predict.gam(gam.REALM, newdata = test, type="response")
fold = 1
nfolds <- 5
case.folds <- rep(1:nfolds,length.out=nrow(DAT))
# divide the cases as evenly as possible
case.folds <- sample(case.folds) # randomly permute the order
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
gam.REALM <- gam(REALM.formula, data=train, family="nb")
preds <- predict.gam(gam.REALM, newdata = test, type="response")
preds
plot(preds, test$S)
plot(log(preds), log(test$S))
plot(log(preds), log(test$S)); abline(a=0, b=1)
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
gam.train <- gam(REALM.formula, data=train, family="nb")
preds <- predict.gam(gam.train, newdata = test, type="response")
plot(log(preds), log(test$S)); abline(a=0, b=1)
# Average the MSEs
bandwidths.cv.mses <- colMeans(fold.mses)
nfolds <- 4
case.folds <- rep(1:nfolds,length.out=nrow(DAT))
# divide the cases as evenly as possible
case.folds <- sample(case.folds) # randomly permute the order
par(mfrow=c(2,2))
for (fold in 1:nfolds) {
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
gam.train <- gam(REALM.formula, data=train, family="nb")
preds <- predict.gam(gam.train, newdata = test, type="response")
plot(log(preds), log(test$S)); abline(a=0, b=1)
}
par(mfrow=c(2,2))
for (fold in 1:nfolds) {
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
gam.train <- gam(REALM.formula, data=train, family="nb")
preds <- predict.gam(gam.train, newdata = train, type="response")
plot(log(preds), log(test$S)); abline(a=0, b=1)
}
nrow(train)
nrow(test)
################################################################################
# Author: Petr Keil
# Email: pkeil@seznam.cz
# Date: Sep 11 2018
################################################################################
#
# Description:
#
################################################################################
# 0. LOAD THE DATA AND THE PACKAGES
################################################################################
# clean the workspace and load the libraries
source("0_libraries_functions_settings.r")
# ------------------------------------------------------------------------------
# load the data
PLT <- read.csv("../Data/Main_dataset_full_detail.csv")
################################################################################
# 1. PREPARE THE DATA FOR THE ANALYSES
################################################################################
# calculate tree density (note the x+1 step!!)
PLT$Tree_dens <- (PLT$N + 1) / PLT$Area_km
# select only the variables of interest from the larger data.frame
DAT <- dplyr::select(PLT, S, Area_km, Tree_dens, min_DBH=min_DBH_cm,
GPP, ET, ANN_T, WARM_T, ISO_T, MIN_P, P_SEAS, ALT_DIF,
ISLAND, REALM=REALM_PK, Lat, Lon, DAT_TYPE, Loc_ID)
# order the data frame by regions and area
DAT <- DAT[order(DAT$REALM),]
# transform area and tree density
DAT$Area_km <- log(DAT$Area_km)
DAT$Tree_dens <- log(DAT$Tree_dens)
# remove NAs
DAT <- DAT[rowSums(is.na(DAT)) == 0,]
# mean and sd of Area (will be used later to bring these to their origina scale)
A.mean <- mean(DAT$Area_km)
A.sd <- sd(DAT$Area_km)
# means and sd of the rest of the variables
centr <- attributes(scale(DAT[,2:12]))$'scaled:center'
scale <- attributes(scale(DAT[,2:12]))$'scaled:scale'
scale.tab <- data.frame(var=names(centr), centr, scale)
write.csv(scale.tab, file="scale_tab.csv", row.names = FALSE)
# do the actual scaling
DAT[,2:12] <- scale(DAT[,2:12])
nrow(DAT)
par(mfrow=c(2,2))
for (fold in 1:nfolds) {
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
gam.train <- gam(REALM.formula, data=test, family="nb")
preds <- predict.gam(gam.train, newdata = train, type="response")
plot(log(preds), log(test$S)); abline(a=0, b=1)
}
nfolds <- 4
case.folds <- rep(1:nfolds,length.out=nrow(DAT))
# divide the cases as evenly as possible
case.folds <- sample(case.folds) # randomly permute the order
par(mfrow=c(2,2))
for (fold in 1:nfolds) {
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
gam.train <- gam(REALM.formula, data=test, family="nb")
preds <- predict.gam(gam.train, newdata = train, type="response")
plot(log(preds), log(test$S)); abline(a=0, b=1)
}
REALM.formula <- S ~ REALM + poly(Area_km,3):REALM +
Tree_dens + Tree_dens:Area_km +
min_DBH + min_DBH:Area_km +
GPP + GPP:Area_km +
ANN_T + ANN_T:Area_km +
ISO_T + ISO_T:Area_km +
MIN_P + MIN_P:Area_km +
P_SEAS + P_SEAS:Area_km +
ALT_DIF + ALT_DIF:Area_km +
ISLAND + ISLAND:Area_km
SMOOTH.formula <- S ~ s(Lat, Lon, by=DAT_TYPE, bs="sos", k=14) +
poly(Area_km, 3) +
Tree_dens + Tree_dens:Area_km +
min_DBH + min_DBH:Area_km +
GPP + GPP:Area_km +
ANN_T + ANN_T:Area_km +
ISO_T + ISO_T:Area_km +
MIN_P + MIN_P:Area_km +
P_SEAS + P_SEAS:Area_km +
ALT_DIF + ALT_DIF:Area_km +
ISLAND + ISLAND:Area_km
nfolds <- 4
case.folds <- rep(1:nfolds,length.out=nrow(DAT))
# divide the cases as evenly as possible
case.folds <- sample(case.folds) # randomly permute the order
par(mfrow=c(2,2))
for (fold in 1:nfolds) {
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
gam.train <- gam(REALM.formula, data=test, family="nb")
preds <- predict.gam(gam.train, newdata = train, type="response")
plot(log(preds), log(test$S)); abline(a=0, b=1)
}
par(mfrow=c(2,2))
for (fold in 1:nfolds) {
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
gam.train <- gam(REALM.formula, data=train, family="nb")
preds <- predict.gam(gam.train, newdata = test, type="response")
plot(log(preds), log(test$S)); abline(a=0, b=1)
}
par(mfrow=c(2,2))
for (fold in 1:nfolds) {
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
gam.train <- gam(REALM.formula, data=train, family="nb")
preds <- predict.gam(gam.train, newdata = train, type="response")
plot(log(preds), log(train$S)); abline(a=0, b=1)
}
par(mfrow=c(2,2))
for (fold in 1:nfolds) {
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
gam.train <- gam(REALM.formula, data=train, family="nb")
preds <- predict.gam(gam.train, newdata = test, type="response")
plot(log(preds), log(test$S)); abline(a=0, b=1)
}
par(mfrow=c(2,2))
for (fold in 1:nfolds) {
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
gam.train <- gam(REALM.formula, data=train, family="nb")
preds <- predict.gam(gam.train, newdata = test, type="response")
plot(log(preds), log(test$S), col=test$DAT_TYPE); abline(a=0, b=1)
}
par(mfrow=c(2,2))
for (fold in 1:nfolds) {
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
gam.train <- gam(SMOOTH.formula, data=train, family="nb")
preds <- predict.gam(gam.train, newdata = test, type="response")
plot(log(preds), log(test$S), col=test$DAT_TYPE); abline(a=0, b=1)
}
par(mfrow=c(2,2))
for (fold in 1:nfolds) {
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
gam.train <- gam(SMOOTH.formula, data=train, family="nb")
preds <- predict.gam(gam.train, newdata = test, type="response")
plot((preds), (test$S), col=test$DAT_TYPE); abline(a=0, b=1)
}
par(mfrow=c(2,2))
for (fold in 1:nfolds) {
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
gam.train <- gam(SMOOTH.formula, data=train, family="nb")
preds <- predict.gam(gam.train, newdata = test, type="response")
plot(log(preds), log(test$S), col=test$DAT_TYPE); abline(a=0, b=1)
}
par(mfrow=c(2,2))
for (fold in 1:nfolds) {
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
gam.train <- gam(SMOOTH.formula, data=train, family="nb")
preds <- predict.gam(gam.train, newdata = test, type="response")
plot( log(test$S),log(preds), col=test$DAT_TYPE); abline(a=0, b=1)
}
nfolds <- 4
case.folds <- rep(1:nfolds,length.out=nrow(DAT))
# divide the cases as evenly as possible
case.folds <- sample(case.folds) # randomly permute the order
par(mfrow=c(2,2))
for (fold in 1:nfolds) {
# What are the training cases and what are the test cases?
train <- DAT[case.folds!=fold,]
test <- DAT[case.folds==fold,]
gam.train <- gam(SMOOTH.formula, data=train, family="nb")
preds <- predict.gam(gam.train, newdata = test, type="response")
plot( log(test$S),log(preds), col=test$DAT_TYPE); abline(a=0, b=1)
}
library(BIEN)
library(sp)
library(rgdal)
# clean the workspace and load the libraries
source("0_libraries_functions_settings.r")
grid5 <- readOGR(dsn = "../Data/GRIDS", layer = "hex5_with_environment")
plot(grid5)
plot(grid5[100,])
plot(grid5); plot(grid5[100,])
plot(grid5); plot(grid5[100,], add=TRUE, fill="red")
plot(grid5); plot(grid5[100,], add=TRUE, col="red")
# select one hexagon
hex.no = 100
plot(grid5); plot(grid5[hex.no,], add=TRUE, col="red")
hex <- plot(grid5[hex.no,])
plot(grid5); plot(grid5[hex.no,], add=TRUE, col="red")
# select one hexagon
hex.no = 200
plot(grid5); plot(grid5[hex.no,], add=TRUE, col="red")
?BIEN
# select one hexagon
hex.no = 200
hex.obs <- BIEN_occurrence_spatialpolygons(hex)
class(hex)
hex
hex <- grid5[hex.no,]
hex.obs <- BIEN_occurrence_spatialpolygons(hex)
hex.obs
nrow(hex.obs)
unique(hex.obs$scrubbed_species_binomial)
length(unique(hex.obs$scrubbed_species_binomial))
BIEN_trait_traitbyspecies(species = "Chloris ciliata",
trait = "whole plant woodiness")
BIEN_trait_list()
BIEN_trait_traitbyspecies(species = "Abarema racemiflora",
trait = "whole plant woodiness")
BIEN_trait_traitbyspecies(species = hex.obs$scrubbed_species_binomial[1:100],
trait = "whole plant woodiness")
head(grid5)
# select one hexagon
hex.no = 200
plot(grid5); plot(grid5[hex.no,], add=TRUE, col="red")
# select one hexagon
hex.no = 230
# select one hexagon
hex.no = 230
plot(grid5); plot(grid5[hex.no,], add=TRUE, col="red")
# select one hexagon
hex.no = 250
plot(grid5); plot(grid5[hex.no,], add=TRUE, col="red")
# select one hexagon
hex.no = 300
plot(grid5); plot(grid5[hex.no,], add=TRUE, col="red")
# select one hexagon
hex.no = 350
plot(grid5); plot(grid5[hex.no,], add=TRUE, col="red")
hex <- grid5[hex.no,]
hex.obs <- BIEN_occurrence_spatialpolygons(hex)
hex.obs
a <- list()
a[1] <- 2
a
a[3] <- 2
a
save(a, file = "BIEN.Rdat")
save(a, file = "BIEN.Rdata")
a["a"] <- 344
a
res <- list()
for(hex.no in 1:nrow(grid5))
{
hex <- grid5[hex.no,]
#hex.obs <- BIEN_occurrence_spatialpolygons(hex)
#res[grid5$id[cell.id]] <- hex.obs
}
res <- list()
for(hex.no in 1:nrow(grid5))
{
hex <- grid5[hex.no,]
plot(grid5); plot(hex, add=TRUE, col="red")
#hex.obs <- BIEN_occurrence_spatialpolygons(hex)
#res[grid5$id[cell.id]] <- hex.obs
}
plot(grid5)
for(hex.no in 1:nrow(grid5))
{
hex <- grid5[hex.no,]
plot(hex, add=TRUE, col="red")
#hex.obs <- BIEN_occurrence_spatialpolygons(hex)
#res[grid5$id[cell.id]] <- hex.obs
}
save(re
plot(grid5)
for(hex.no in 1:nrow(grid5))
{
hex <- grid5[hex.no,]
plot(hex, add=TRUE, col="red")
Sys.sleep(0.5)
#hex.obs <- BIEN_occurrence_spatialpolygons(hex)
#res[grid5$id[cell.id]] <- hex.obs
}
plot(grid5)
for(hex.no in 1:nrow(grid5))
{
hex <- grid5[hex.no,]
plot(hex, add=TRUE, col="red")
Sys.sleep(0.1)
#hex.obs <- BIEN_occurrence_spatialpolygons(hex)
#res[grid5$id[cell.id]] <- hex.obs
}
# clean the workspace and load the libraries
source("0_libraries_functions_settings.r")
library(BIEN)
grid5 <- readOGR(dsn = "../Data/GRIDS", layer = "hex5_with_environment")
# ------------------------------------------------------------------------------
res <- list()
plot(grid5)
for(hex.no in 1:nrow(grid5))
{
hex <- grid5[hex.no,]
plot(hex, add=TRUE, col="red")
Sys.sleep(0.1)
hex.obs <- BIEN_occurrence_spatialpolygons(hex)
res[grid5$id[cell.id]] <- hex.obs
}
save(res, file = "BIEN_occur_grid5.Rdata")
res <- list()
plot(grid5)
for(hex.no in 1:nrow(grid5))
{
hex <- grid5[hex.no,]
plot(hex, add=TRUE, col="red")
Sys.sleep(0.1)
hex.obs <- BIEN_occurrence_spatialpolygons(hex)
res[grid5$id[hex.no]] <- hex.obs
}
res
names(res)
class(res)
res[1]
res[2]
length(res[2])
length(res[2][])
length(res[[2]][])
################################################################################
# Author: Petr Keil
# Email: pkeil@seznam.cz
# Date: April 26 2018
################################################################################
# Description: Here is where model SMOOTH is used to generate predictions to the
# regular global network of 1 ha plots, and to the grid of large hexagons.
################################################################################
# clean the workspace and load the libraries
source("0_libraries_functions_settings.r")
################################################################################
### Read, transform and scale the data
# read the data
pts <- read.csv(file="../Data/GRIDS/Fine_points_with_environment.csv")
grid5 <- readOGR(dsn = "../Data/GRIDS", layer = "hex5_with_environment")
grid5 <- spTransform(x = grid5, CRSobj = WGS84)
# -----------------------------------------
pts$Tree_dens <- (pts$TREE_DENS + 1) / pts$A # calculate tree density (note the x+1 step!!)
pts <- data.frame(pts, Area_km = 0.01, min_DBH = 0, DAT_TYPE = "Plot")
# tree density at the grid level
grid5$Tree_dens <- (grid5$TREE_DENS + 1) / grid5$LandArea
grid5@data <- data.frame(grid5@data, min_DBH = 0, DAT_TYPE = "Country")
# -----------------------------------------
pts <- dplyr::select(pts, Area_km, Tree_dens, min_DBH,
GPP, ANN_T, ISO_T, MIN_P, P_SEAS, ALT_DIF,
ISLAND, Lat, Lon, DAT_TYPE) %>%
mutate(Area_km = log(Area_km), Tree_dens=log(Tree_dens))
grid5.dat <- dplyr::select(grid5@data, Area_km = LandArea, Tree_dens, min_DBH,
GPP, ANN_T, ISO_T, MIN_P, P_SEAS, ALT_DIF,
ISLAND, Lat, Lon, DAT_TYPE) %>%
mutate(Area_km = log(Area_km), Tree_dens=log(Tree_dens))
# get the scaling constants that were used to scale the raw plot and country data:
scal.tab <- read.csv("scale_tab.csv")
scal.tab <- scal.tab[scal.tab$var %in% c("ET","WARM_T") == FALSE,]
# scale the grid data in the same way as the original data
pts[,1:9] <- scale(pts[,1:9],
center = scal.tab$centr,
scale = scal.tab$scale)
grid5.dat[,1:9] <- scale(grid5.dat[,1:9],
center = scal.tab$centr,
scale = scal.tab$scale)
load("../STAN_models/brms_SMOOTH.Rdata")
getwd()
load("../STAN_models/gam_SMOOTH.Rdata")
load("../STAN_models/brms_SMOOTH.Rdata")
load("/homes/pk33loci/Dropbox/JON_CHASE/Data_and_code_repository/STAN_models/brms_SMOOTH.RData")
load("../STAN_models/brms_SMOOTH.RData")
objects()
grid.pred.S <- predict(brm.SMOOTH,
newdata = grid5.dat,
type="response")
warnings()
grid.pred.S
?predict.brm
?predict.brms
?predict
grid.pred.S <- predict(gam.SMOOTH,
newdata = grid5.dat,
type="response")
grid.pred.S.brm <- predict.brmsfit(brm.SMOOTH,
newdata = grid5.dat)
grid.pred.S.brm <- predict(brm.SMOOTH,
newdata = grid5.dat)
brid.pred.S
grid.pred.S
data.frame(grid.pred.S, grid.pred.S.brm)
?predict.brmsfit
